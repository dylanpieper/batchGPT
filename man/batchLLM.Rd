% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/batchLLM.R
\name{batchLLM}
\alias{batchLLM}
\title{batchLLM}
\usage{
batchLLM(
  df_name,
  col_name,
  prompt,
  batch_size = 10,
  LLM = "openai",
  model = "gpt-4o-mini",
  temperature = 0.5,
  attempts = 1,
  log_name = "batchLLM-log",
  case_convert = NULL,
  hash_algo = "crc32c",
  ...
)
}
\arguments{
\item{df_name}{A string for the name of a data frame.}

\item{col_name}{A string for the name of a column.}

\item{prompt}{A system prompt for the GPT model.}

\item{batch_size}{The number of rows to process in each batch. Default is 10.}

\item{LLM}{A string for the name of the LLM with the options: "openai" and "anthropic". Default is "openai".}

\item{model}{A string for the name of the model from the LLM. Default is "gpt-4o-mini".}

\item{temperature}{A temperature for the GPT model. Default is .5.}

\item{attempts}{The maximum number of loop retry attempts. Default is 1.}

\item{log_name}{A string for the name of the log without the \code{.rds} file extension. Default is "batchLLM-log".}

\item{case_convert}{A string for the case conversion of the output with the options: "upper", "lower", or NULL (no change). Default is NULL.}

\item{hash_algo}{A string for a hashing algorithm from the 'digest' package. Default is \code{crc32c}.}
}
\value{
Assigns a column with a hashed name containing the text completion output.
Writes the output and metadata to the log file after each batch in a nested list format:
\itemize{
  \item \code{data}: A list containing:
  \itemize{
    \item \code{phrases_533e145b}: A list representing a tibble with a hashed name:
    \itemize{
      \item \code{output}: A tibble with the original text and generated completions.
      \item \code{metadata}: A list with details for each generated column:
      \itemize{
        \item \code{user_2894a19c}: A list representing a generated column with a hashed name:
        \itemize{
          \item \code{batches}: A list of lists, each representing a batch, with elements:
          \itemize{
            \item \code{batch_number}: The batch number.
            \item \code{status}: The status of the batch (e.g., "In Progress", "Completed").
            \item \code{timestamp}: Timestamp of the batch processing.
            \item \code{total_time}: Total running time in the batches.
            \item \code{prompt}: The prompt used for the batch.
            \item \code{model}: The model used for generating completions.
            \item \code{temperature}: The temperature parameter used.
          }
          \item \code{last_batch}: The last successfully completed batch number.
          \item \code{total_time}: The last total time in the batches.
        }
      }
    }
  }
}
}
\description{
Batch process Large Language Model (LLM) text generation models on data frames with local storage and metadata.
Effortlessly loop across rows of a column and generate text completions with minimal supervision.
The package currently supports OpenAI GPT, Anthropic Claude, and Google Gemini models, with built-in delays for API etiquette.
The package addresses challenges in text processing by offering features such as saving batches and metadata in a locally stored log file after each batch.
Compare the output of different LLMs and implement a Shiny App Addin.
Use cases include natural language processing tasks such as sentiment analysis, thematic analysis, classification, labeling or tagging, and language translation.
}
\examples{
library(batchLLM)

Sys.setenv(OPENAI_API_KEY = "...")

phrases <- data.frame(
  user = c(
    "The world is a sphere, and I love it.",
    "The world is a sphere, and that is science.",
    "The world is flat, and round earth is a conspiracy."
  )
)

batchLLM(
  df_name = "phrases",
  col_name = "user",
  prompt = "Classify the sentiment using one word: positive, negative, or neutral"
)

print(phrases)
}
