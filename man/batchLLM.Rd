% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/batchLLM.R
\name{batchLLM}
\alias{batchLLM}
\title{batchLLM}
\usage{
batchLLM(
  df_name,
  col_name,
  prompt,
  LLM = "openai",
  model = "gpt-4o-mini",
  temperature = 0.5,
  batch_delay = "random",
  batch_size = 10,
  attempts = 1,
  log_name = "batchLLM-log",
  hash_algo = "crc32c",
  case_convert = NULL,
  ...
)
}
\arguments{
\item{df_name}{A string for the name of a data frame.}

\item{col_name}{A string for the name of a column.}

\item{prompt}{A system prompt for the GPT model.}

\item{LLM}{A string for the name of the LLM with the options: "openai", "anthropic", and "google". Default is "openai".}

\item{model}{A string for the name of the model from the LLM. Default is "gpt-4o-mini".}

\item{temperature}{A temperature for the GPT model. Default is .5.}

\item{batch_delay}{A string for the batch delay with the options: "random", "min", and "sec". Numeric examples include "1min" and "30sec". Default is "random".}

\item{batch_size}{The number of rows to process in each batch. Default is 10.}

\item{attempts}{The maximum number of loop retry attempts. Default is 1.}

\item{log_name}{A string for the name of the log without the \code{.rds} file extension. Default is "batchLLM-log".}

\item{hash_algo}{A string for a hashing algorithm from the 'digest' package. Default is \code{crc32c}.}

\item{case_convert}{A string for the case conversion of the output with the options: "upper", "lower", or NULL (no change). Default is NULL.}
}
\value{
Assigns a column with a hashed name containing the text completion output.
Writes the output and metadata to the log file after each batch in a nested list format:
\itemize{
  \item \code{data}: A list containing:
  \itemize{
    \item \code{phrases_533e145b}: A list representing a tibble with a hashed name:
    \itemize{
      \item \code{output}: A tibble with the original text and generated completions.
      \item \code{metadata}: A list with details for each generated column:
      \itemize{
        \item \code{user_2894a19c}: A list representing a generated column with a hashed name:
        \itemize{
          \item \code{batches}: A list of lists, each representing a batch, with elements:
          \itemize{
            \item \code{batch_number}: The batch number.
            \item \code{status}: The status of the batch (e.g., "In Progress", "Completed").
            \item \code{timestamp}: Timestamp of the batch processing.
            \item \code{total_time}: Total running time in the batches.
            \item \code{prompt}: The prompt used for the batch.
            \item \code{model}: The model used for generating completions.
            \item \code{temperature}: The temperature parameter used.
          }
          \item \code{last_batch}: The last successfully completed batch number.
          \item \code{total_time}: The last total time in the batches.
        }
      }
    }
  }
}
}
\description{
Batch process Large Language Model (LLM) text completions using data frame rows, with automated storage of results and metadata.
The package currently supports OpenAI's GPT, Anthropic's Claude, and Google's Gemini models, with built-in delays for API rate limiting
The package provides advanced text processing features, including automatic logging of batches and metadata to local files, side-by-side comparison of outputs from different LLMs, and integration of a user-friendly Shiny App Addin.
Use cases include natural language processing tasks such as sentiment analysis, thematic analysis, classification, labeling or tagging, and language translation.
}
\examples{
library(batchLLM)

Sys.setenv(OPENAI_API_KEY = "")

phrases <- data.frame(
  user = c(
    "The world is a sphere, and I love it.",
    "The world is a sphere, and that is science.",
    "The world is flat, and round earth is a conspiracy."
  )
)

batchLLM(
  df_name = "phrases",
  col_name = "user",
  prompt = "Classify the sentiment using one word: positive, negative, or neutral"
)

print(phrases)
}
