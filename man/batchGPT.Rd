% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/batchGPT.R
\name{batchGPT}
\alias{batchGPT}
\title{Batch GPT}
\usage{
batchGPT(
  input,
  prompt,
  batch_size = 10,
  attempts = 1,
  model = "gpt-3.5-turbo-0125",
  temperature = 0.5
)
}
\arguments{
\item{input}{A vector extracted from a data frame using the $ operator. This function does not support piping.}

\item{prompt}{A system prompt for the GPT model.}

\item{batch_size}{The number of rows to process in each batch.}

\item{attempts}{The maximum number of attempts in case of errors.}

\item{model}{An OpenAI model.}

\item{temperature}{A temperature for the GPT model.}
}
\value{
Returns the original data frame and adds a column with the GPT output (gpt_output). Writes progress to \code{gpt_output.RDS}.
}
\description{
Use OpenAI's GPT model to conduct natural language tasks using rows from a column as the input.
Completions are batched to save your progress in case of an error or interruption.
For API etiquette, there is a delay between each completion and each batch.
}
\examples{
library(batchGPT)

Sys.setenv(OPENAI_API_KEY = "...")

phrases <- dplyr::tibble(user = c("love the world", "screw the world", "the world is a sphere"))

batchGPT(
  input = phrases$user,
  prompt = "classify the sentiment using one word: positive, negative, or neutral"
)

print(phrases)
}
