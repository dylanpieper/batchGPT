% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/batchGPT.R
\name{batchGPT}
\alias{batchGPT}
\title{Batch GPT}
\usage{
batchGPT(
  input,
  prompt,
  batch_size = 10,
  attempts = 1,
  model = "gpt-3.5-turbo-0125",
  temperature = 0.1
)
}
\arguments{
\item{input}{A vector from a data frame defined by the $ operator. Data cannot be piped.}

\item{prompt}{A system prompt for the GPT model.}

\item{batch_size}{The number of rows to process in each batch. Default is 10.}

\item{attempts}{The maximum number of attempts in case of errors. Default is 1.}

\item{model}{An OpenAI model. Default is gpt-3.5-turbo-0125.}

\item{temperature}{A temperature for the GPT model. Default is 0.1.}
}
\value{
Returns the original data frame and adds a column with the GPT output (gpt_output). Writes progress to \code{gpt_output.RDS}.
}
\description{
Use OpenAI's GPT model to conduct natural language tasks using rows from a column as the input.
Completions are batched to save your progress in case of an error or interruption.
For API etiquette, there is a delay between each completion and each batch.
}
\examples{
library(batchGPT)

Sys.setenv(OPENAI_API_KEY = "...")

phrases <- dplyr::tibble(user = c("love the world", "screw the world", "the world is a sphere"))

batchGPT(
  input = phrases$user,
  prompt = "classify the sentiment using one word: positive, negative, or neutral"
)

print(phrases)
}
